{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LCTc62UvNaPH"
   },
   "source": [
    "# Research Methods <br>UHH - Knowledge Technology Research Group - WiSe 2022/2023\n",
    "## Assignment #2 - Empirical Studies & EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qC0JVio8NaPN"
   },
   "source": [
    "***\n",
    "### Group: E\n",
    "### Names of members: Parvin Abbasi, Aron Jinga, Atharva Phatak\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AbYwvvJINaPO"
   },
   "source": [
    "### Instructions:\n",
    "\n",
    "Please answer the questions below. Copy this notebook and enter your answers underneath each task description, inserting cells as needed. You may use a combination of [python 3](https://www.python.org), [markdown](http://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Working%20With%20Markdown%20Cells.html), and [LaTex](https://towardsdatascience.com/write-markdown-latex-in-the-jupyter-notebook-10985edb91fd) to formulate your responses. In order to successfully complete the assignment, you will need the lecture material provided in the [RM moodle course](https://lernen.min.uni-hamburg.de/course/view.php?id=2637), especially L02 & L03.\n",
    "\n",
    "**Make sure to use only a copy of this notebook for your answers instead of a new/blank notebook.** \n",
    "\n",
    "### Grading Criteria:\n",
    "\n",
    "In order to successfully pass this assignment, you will need **at least a total of 70 points out of 100 points**, and every task has to be tackled.\n",
    "\n",
    "### Submission:\n",
    "\n",
    "Please upload the following two files **until Tuesday, November 8, 2022, 20:00 CET (Germany)** together in a .zip archive in moodle:\n",
    "1. a (single) copy of this jupyter notebook containing your answers for all tasks (file extension: .ipynb)\n",
    "2. an [exported PDF document](https://jupyterlab.readthedocs.io/en/stable/user/export.html) of the jupyter notebook (file extension: .pdf)\n",
    "\n",
    "### Presentation:\n",
    "\n",
    "Make sure that each (!) group member takes part in solving this assignment and is prepared to answer questions and/or present solutions from your submitted notebook during our assignment revision meeting scheduled for **Wednesday, November 16, 2022, 10:00 - 13:00 CET (Germany)**.\n",
    "\n",
    "### File Naming:\n",
    "\n",
    "Add the group letter to the file name prior to submission. For example, if your group letter is \"A\" (see group selection in moodle), you would use the following filename: \n",
    "1. RM_A02_Group_A.ipynb\n",
    "2. RM_A02_Group_A.pdf\n",
    "\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "id": "YF7rqqw6Ntaa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: unrecognized arguments: # to show the plots\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sbs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WlG8pL3wPfJH"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'Datasets/CRU_data.csv')\n",
    "sbs.set_theme()\n",
    "months = ['JAN', 'FEB', 'MAR', 'APR', 'MAY', 'JUN', 'JUL', 'AUG', 'SEP', 'OCT', 'NOV', 'DEC']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qgwtsll0NaPO"
   },
   "source": [
    "#### Task 1 **[10 points] Data Scales**\n",
    "\n",
    "1. For each of the features in the CRU dataset (e.g., precipitation), identify all scales of data whose definition is valid for all entries in the columns that belong to that feature. Create a table using python code that contains all features as rows, data scales as columns, and binary table entries indicating whether the feature values (i.e., column entries in the database) correspond to the data scale or not.\n",
    "2. For each of the features, briefly explain to which of the errors mentioned in the lecture this feature is prone. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tM4bsPQwPpSD"
   },
   "outputs": [],
   "source": [
    "#Solution 1\n",
    "#task1.1:\n",
    "df_scale = pd.DataFrame({'Feature':  ['Country', 'Year', 'Tempreture', 'Wet days', 'Precipitation' ],\n",
    "        'Categorical': ['1', '0', '0', '0', '0'],\n",
    "        'Interval': ['0', '1', '1', '0', '0'],\n",
    "        'Ratio': ['0', '0', '0', '1', '1'],\n",
    "        'Ordinal': ['0', '0', '0', '0', '0']})\n",
    "df_scale = df_scale.set_index('Feature')\n",
    "df_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### task 1.2 :\n",
    " Measurement error can happen for temperature and wet days and precipitation because broken equipment can record wrong values. \n",
    "Sampling error can happen for temperature and wet days and precipitation because gathering data from different cities will obtain different results. \n",
    "For example, in 2020, only Berlin and Hamburg and Stuttgart are recorded but in 1996, other three cities. \n",
    "For country and year no error is prone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H8FA4KTNNaPR"
   },
   "source": [
    "#### Task 2 **[10 points] Types of Experiments**\n",
    "\n",
    "Different types of studies and experiments were discussed in the lecture. With respect to climate data, state whether it is possible to conduct the following experiments given below. Briefly explain your reasoning and give an example for each of the four types.\n",
    "\n",
    "1. Exploratory study\n",
    "2. Assessment study\n",
    "3. Observation experiments\n",
    "4. Manipulation experiments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xx4G08RgNaPR"
   },
   "source": [
    "1. Exploratory study: \n",
    "    By looking at data we can see that the temperature  is increasing in the long term and the weather pattern is visible. \n",
    "    Also some countries are colder than the others depending on their location. \n",
    "    Countries that are located around the equator experience hot weather throughout the year. \n",
    "    It is because the sun remains almost directly overhead everyday.\n",
    "    Countries that are further North or South of the equator experience a change in seasons, when hot weather follows cold weather.\n",
    "\n",
    "2. Assessment study: In assessment study we can test data's limit. The minimum recorded value for temperature is -89.2°C (-128.6°F) but in the dataset we can see -999 which is wrong. \n",
    "\n",
    "3. Observation experiments: \n",
    "\n",
    "4. Manipulation experiments: We cannot change the temperature and precipitation and so on to manipulate data \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h0RqHdkpNaPS"
   },
   "source": [
    "#### Task 3 **[40 points] Visualization**\n",
    "\n",
    "Plot the four statistics given below using suitable python packages:\n",
    "\n",
    "1. Timeline of cumulative precipitation over the course of the year 2020. _(i)_ world-wide and _(ii)_ per country.\n",
    "2. Average precipitation per wetday per country in 2020.\n",
    "3. Climate diagram based on the average data from the last decade (2011 - 2020) for one country of your choice.<br> _Note: Include the amount of precipitation as well as min, mean, and max temperature._\n",
    "4. Frequency distribution of mean temperatures in Germany in the timespans (i) 1960-1980 and (ii) 2000-2020. <br> _Note: Use appropriate, common bins for both diagrams._\n",
    "\n",
    "As a reminder, the following instructions will apply to **all visualization tasks** as part of the RM course: Make sure to use appropriate plot types for visualization (e.g., histogram, bar plot, scatter plot, line plot, ...) and proper axis labeling/scaling. Add a legend to each plot to facilitate the viewer's understanding. Make sure to describe/interpret the outcome of your visualization.\n",
    "\n",
    "_Hint: It might be helpful to use the [wide__to__long](https://pandas.pydata.org/docs/reference/api/pandas.wide_to_long.html) function in pandas to format the data for plotting!_ <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 457
    },
    "id": "wY3sHlLrNaPT",
    "outputId": "082e8bfd-bbb7-4c09-8921-aab170c9880c",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###########################################\n",
    "#Solution 1 start\n",
    "df_indexed = df[df['YEAR'] == 2020].set_index(\"COUNTRY\")\n",
    "df_a = df_indexed.iloc[:,65:77]\n",
    "df_b = np.cumsum(df_a.T)\n",
    "df_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "id": "_l-FM3urNaPT",
    "outputId": "ac63dde9-bab9-4122-e706-d0d0e3902f61",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Plotting of the graph for task 1\n",
    "g = sbs.relplot(data=df_b, kind='line', height = 6, aspect = 2, markers = True, dashes = False )\n",
    "g.set_xticklabels(months) #setting the x ticks to make them easier to read\n",
    "g.set_xlabels(\"Months\")\n",
    "g.set_ylabels(\"Precipitations\")\n",
    "g.set(title = \"World's precipitation for 2020\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 382
    },
    "id": "kUut5jXSNaPU",
    "outputId": "ec975ef7-ab61-4d5f-f4dd-8a0f059ad80b",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ctr_precip = sbs.relplot(data = np.cumsum(df_a.sum()),kind='line', height = 6, aspect = 2, markers = True, dashes = False )\n",
    "ctr_precip.set_xticklabels(months) #setting the x ticks to make them easier to read\n",
    "ctr_precip.set_xlabels(\"Months\")\n",
    "ctr_precip.set_ylabels(\"Precipitations\")\n",
    "ctr_precip.set(title = \"Cumulative precipitation for the entire world in 2020\")\n",
    "\n",
    "#######################\n",
    "# Solution 1 end \n",
    "######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 457
    },
    "id": "330z9z1nNaPU",
    "outputId": "8087a7cc-08e9-443c-edba-46d879725715",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#### Task 2 ####\n",
    "df_indexed = df[df['YEAR'] == 2020].set_index(\"COUNTRY\")\n",
    "df_precip = df_indexed.iloc[:,65:77]\n",
    "df_wet = df_indexed.iloc[:,49:61]\n",
    "df_wet[\"Total Precipitation\"] = df_precip.sum(axis=1)\n",
    "df_wet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in df_wet.columns:\n",
    "    df_wet[i] = df_wet['Total Precipitation']/df_wet[i]\n",
    "df_wet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe in the table for the wet_days in september, Egypt has an infinity point, having no wet days in the month of September. As such, the plot will not have any data for Egypt in September and it will connect the August and October directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "id": "FrzGs1oeNaPV",
    "outputId": "0ac98057-9c1b-461d-9d3f-954b2082c056"
   },
   "outputs": [],
   "source": [
    "wet_day = sbs.relplot(data = df_wet.drop(\"Total Precipitation\",axis=1).T, kind = 'line', height = 6, aspect = 2, markers = True, dashes = False)\n",
    "wet_day.set_xticklabels(months)\n",
    "wet_day.set_xlabels(\"Months\")\n",
    "wet_day.set_ylabels(\"Average precipitation\")\n",
    "#Solution 2 end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Task 3 ###\n",
    "db = df[(df['COUNTRY'] == 'INDIA') & (df['YEAR'].between(2011,2020))].set_index(\"COUNTRY\")\n",
    "# Created dataset for india between 2011 and 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Climate graphs\n",
    "df_india = df[df['COUNTRY'] == 'INDIA'].query(\"YEAR >2010\").set_index(\"YEAR\").drop(\"COUNTRY\",axis=1)\n",
    "df_india_mean_temp = df_india.iloc[:,:12]\n",
    "df_india_precip_pc = df_precip.iloc[1:2].rename(columns = {'PRECIP_JAN':'JANUARY', 'PRECIP_FEB':'FEBRUARY', 'PRECIP_MAR' : 'MARCH',\n",
    "                                                           'PRECIP_APR':'APRIL','PRECIP_MAY':'MAY','PRECIP_JUN':'JUNE','PRECIP_JUL':'JULY',\n",
    "                                                           'PRECIP_AUG':'AUGUST','PRECIP_SEP':'SEPTEMBER','PRECIP_OCT':'OCTOBER','PRECIP_NOV':'NOVEMBER',\n",
    "                                                           'PRECIP_DEC':'DECEMBER'})\n",
    "\n",
    "#ax1 = sbs.set_style(style=None, rc=None )\n",
    "fig, ax1 = plt.subplots(figsize=(14,6))\n",
    "sbs.lineplot(data=df_india_mean_temp.sum(axis=0)/10,color='red',marker = 'o',sort=False,ax=ax1)\n",
    "ax1.set(ylabel=\"Mean Temperature\")\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set(ylabel = \"Precipitation\")\n",
    "sbs.barplot(data=df_india_precip_pc,ax=ax2,alpha=0.5,color='blue')\n",
    "\n",
    "\n",
    "df_india_min_temp = df_india.iloc[:,16:28]\n",
    "fig, ax1 = plt.subplots(figsize=(14,6))\n",
    "sbs.lineplot(data=df_india_min_temp.sum(axis=0)/10,color='red',marker = 'o',sort=False,ax=ax1)\n",
    "ax1.set(ylabel=\"Minimum Temperature\")\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set(ylabel = \"Precipitation\")\n",
    "sbs.barplot(data=df_india_precip_pc,ax=ax2,alpha=0.5,color='blue')\n",
    "\n",
    "df_india_max_temp = df_india.iloc[:,32:44]\n",
    "fig, ax1 = plt.subplots(figsize=(14,6))\n",
    "sbs.lineplot(data=df_india_max_temp.sum(axis=0)/10,color='red',marker = 'o',sort=False,ax=ax1)\n",
    "ax1.set(ylabel=\"Maximum Temperature\")\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set(ylabel = \"Precipitation\")\n",
    "sbs.barplot(data=df_india_precip_pc,ax=ax2,alpha=0.5,color='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iqugCoWsNaPV"
   },
   "source": [
    "#### Task 4 **[40 points] EDA**\n",
    "\n",
    "Following the Titanic example from the lecture, we want to gain first insights into multivariate EDA. We want to see if the climate warming is different between countries. For this purpose, take the following steps using python to answer the question **whether the number of warmer/colder months (compared to 50 years ago) changes between countries and whether there is a difference between decades.**\n",
    "\n",
    "For this task use the data from Egypt and Belarus starting from the year 1961.\n",
    "\n",
    "1. For each month, calculate if it was warmer or colder compared to the same month 50 years ago.\n",
    "2. Create two contingency tables of **total number of warmer and colder months per country** (one containing the absolute counts and the second one containing row and column proportions).\n",
    "3. Create another two contingency tables of **total number of warmer and colder months per decade** (one containing the absolute counts and the second one containing row and column proportions).\n",
    "4. Plot a histogram or bar chart that shows the **total number of warmer months by country and decade**. _Hint: The usage of different colors might help a lot!_\n",
    "5. Now combine the contingency tables of task 4.2 and 4.3 (see Titanic example discussed in the EDA lecture), so that you have a subdivision into countries by decade, with absolute counts and row/column proportions.\n",
    "6. Calculate the expected frequencies $f_e$ for each conjunct event in the contingency table from task 4.5 and create a copy of the table from task 4.5 containing the $f_e$ values.\n",
    "7. Calculate $\\chi²_{Egypt}$ and $\\chi²_{Belarus}$ and interpret.\n",
    "8. What does a small $\\chi²$ value mean? What if it's zero? Explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s3WhaYNbNaPW"
   },
   "outputs": [],
   "source": [
    "df_egypt = df[df[\"COUNTRY\"] == \"EGYPT\"].iloc[:,:14].reset_index().drop(\"index\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "m=calendar.month_name[1:]\n",
    "year = []\n",
    "months = m*60\n",
    "result = []\n",
    "country = [\"EGYPT\" for i in range(0,720)]\n",
    "for i in range(60,120):\n",
    "    for j in df_egypt.columns[2:]:\n",
    "        #print(i,j)\n",
    "        year.append(1901+i)\n",
    "        if(df_egypt.loc[i,j] > df_egypt.loc[i-50,j]):\n",
    "            result.append(\"Warmer\")\n",
    "        else:\n",
    "            result.append(\"Colder\")\n",
    "data = {\"COUNTRY\":country,\"YEAR\":year,\"MONTH\":months,\"RESULT\":result}\n",
    "df_egypt_warmer = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_belarus = df[df[\"COUNTRY\"] == 'BELARUS'].iloc[:,:14].reset_index().drop(\"index\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "m=calendar.month_name[1:]\n",
    "year = []\n",
    "months = m*60\n",
    "result = []\n",
    "country = [\"BELARUS\" for i in range(0,720)]\n",
    "for i in range(60,120):\n",
    "    for j in df_belarus.columns[2:]:\n",
    "        #print(i,j)\n",
    "        year.append(1901+i)\n",
    "        if(df_belarus.loc[i,j] > df_belarus.loc[i-50,j]):\n",
    "            result.append(\"Warmer\")\n",
    "        else:\n",
    "            result.append(\"Colder\")\n",
    "data = {\"COUNTRY\":country,\"YEAR\":year,\"MONTH\":months,\"RESULT\":result}\n",
    "df_belarus_warmer = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pd.concat([df_egypt_warmer,df_belarus_warmer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "decades1 = [\"1961-1970\" for i in range(0,120)]\n",
    "decades2 = [\"1971-1980\" for i in range(0,120)]\n",
    "decades3 = [\"1981-1990\" for i in range(0,120)]\n",
    "decades4 = [\"1991-2000\" for i in range(0,120)]\n",
    "decades5 = [\"2001-2010\" for i in range(0,120)]\n",
    "decades6 = [\"2011-2020\" for i in range(0,120)]\n",
    "\n",
    "decades = decades1 + decades2 + decades3 + decades4 + decades5 + decades6\n",
    "\n",
    "final_decades = (decades + decades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot insert DECADE, already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17032\\2638046744.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfinal_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"DECADE\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfinal_decades\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36minsert\u001b[1;34m(self, loc, column, value, allow_duplicates)\u001b[0m\n\u001b[0;32m   4441\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_duplicates\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4442\u001b[0m             \u001b[1;31m# Should this be a different kind of error??\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4443\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"cannot insert {column}, already exists\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4444\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4445\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"loc must be int\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot insert DECADE, already exists"
     ]
    }
   ],
   "source": [
    "final_data.insert(2,\"DECADE\",final_decades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.2\n",
    "pd.crosstab(final_data.COUNTRY,final_data.RESULT,margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.3\n",
    "pd.crosstab(final_data.DECADE,final_data.RESULT,margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.5\n",
    "cross_data = pd.crosstab([final_data.COUNTRY,final_data.DECADE],final_data.RESULT,margins=True)\n",
    "cross_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.6\n",
    "fe_data = cross_data.copy(deep=True)\n",
    "fe_data = fe_data.reset_index()\n",
    "fe_cold = np.round(120*613/1440)\n",
    "fe_warm = np.round(120*827/1440)\n",
    "for j in [\"Colder\",\"Warmer\"]:\n",
    "    for i in range(0,12):\n",
    "        if(j==\"Colder\"):\n",
    "            fe_data.loc[i,j] = fe_cold\n",
    "        elif(j==\"Warmer\"):\n",
    "            fe_data.loc[i,j] = fe_warm\n",
    "fe_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.7\n",
    "cross_data = cross_data.reset_index()\n",
    "chi_squared_belarus = 0\n",
    "for j in [\"Colder\",\"Warmer\"]:\n",
    "    for i in range(0,6):\n",
    "        chi_squared_belarus += np.square(cross_data.loc[i,j]-fe_data.loc[i,j])/fe_data.loc[i,j]\n",
    "chi_squared_egypt = 0\n",
    "for j in [\"Colder\",\"Warmer\"]:\n",
    "    for i in range(6,12):\n",
    "        chi_squared_egypt += np.square(cross_data.loc[i,j]-fe_data.loc[i,j])/fe_data.loc[i,j]\n",
    "print(chi_sqaured_belarus)\n",
    "print(chi_sqaured_egypt)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "qgwtsll0NaPO",
    "H8FA4KTNNaPR"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
